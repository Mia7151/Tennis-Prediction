{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda4c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from lxml import etree\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f6cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "###nltk.download('stopwords')\n",
    "###nltk.download('punkt')\n",
    "###nltk.download('averaged_perceptron_tagger')\n",
    "###nltk.download('wordnet')\n",
    "###nltk.download('omw-1.4')\n",
    "###nltk.download('maxent_ne_chunker')\n",
    "###nltk.download('words')\"\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547af2d5",
   "metadata": {},
   "source": [
    "## 1. read wta player styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read\n",
    "\n",
    "path = '/Users/liuyiwu/540/project/player_style_male_and_female/player_style_female/'\n",
    "name = []\n",
    "data = []\n",
    "\n",
    "for file_name in os.listdir(path):\n",
    "    if file_name == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    f = open(path + file_name, encoding = 'utf-8')\n",
    "    a = []\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        a.append(line.replace(\"\\n\", \"\"))\n",
    "        f.close()\n",
    "    name.append(file_name)\n",
    "    data.append(''.join(a))\n",
    "\n",
    "playing_style = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fcbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "### new stopwords selected based on frequency in the corpus\n",
    "new_stopwords = ['serv','play','court','game','also','player','style','use','ball',\n",
    "                 'allow','tour','describ','although','time','howev','wta','atp','note',\n",
    "                 'consid','career','finish','year','need','prefer','said','take','number',\n",
    "                 'employ','come','despit','skill','set','lot','record','result','could','comment',\n",
    "                 'except','made','includ','sinc','per','somtim','amount','develop','extrem','even',\n",
    "                 'bank','work','australian','feel','regard','favorit','world','among','much','instead',\n",
    "                 'hour','em','whose','think','later','put','would','women','help','though','way','american',\n",
    "                 'interview','alway','ever','look','she','almost','peopl','server','place','refer','problem',\n",
    "                 'either','rather','keep','away','still','enough','someth','thing','john','kvitová','toward',\n",
    "                 'see','util','build','began','level','unlike','mayb','solid','template', 'citation', \n",
    "                 'percentage', 'surface', 'us', 'french', 'open', 'serena', 'weakness', 'venus', 'wimbledon']\n",
    "\n",
    "for i in new_stopwords:\n",
    "    stopwords.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7cb01",
   "metadata": {},
   "source": [
    "## 2. tokenization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19151d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# tokenization and stemming\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string\n",
    "    #将所有stopwords(无意义)的词语删除\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    #将所有数字删除\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4675fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dolehid', 'aggress', 'baselin', 'known', 'strong', 'serv', 'power', 'groundstrok', 'use', 'hit', 'high', 'winner', 'forehand', 'particular', 'one', 'best', 'shot', 'alreadi', 'advanc', 'teenag']\n"
     ]
    }
   ],
   "source": [
    "print(tokenization_and_stemming(playing_style[0])[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59326d",
   "metadata": {},
   "source": [
    "## 3. tokenization and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a3d785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 获取单词的词性\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def tokenization_and_lemmatization(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string\n",
    "    #将所有stopwords(无意义)的词语删除\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    #将所有数字删除\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    tags = pos_tag(filtered_tokens) # 获取单词词性\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatization = []\n",
    "    \n",
    "    #lemmatization\n",
    "    for tag in tags:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmatization.append(wnl.lemmatize(tag[0], pos=wordnet_pos)) # 词形还原\n",
    "    \n",
    "    return lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a93f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dolehide',\n",
       " 'aggressive',\n",
       " 'baseliner',\n",
       " 'know',\n",
       " 'strong',\n",
       " 'serve',\n",
       " 'powerful',\n",
       " 'groundstrokes',\n",
       " 'us',\n",
       " 'hit',\n",
       " 'high',\n",
       " 'winner',\n",
       " 'forehand',\n",
       " 'particular',\n",
       " 'one',\n",
       " 'best',\n",
       " 'shot',\n",
       " 'already',\n",
       " 'advanced',\n",
       " 'teenager']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization_and_lemmatization(playing_style[0])[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3eb7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dolehide is an aggressive baseliner.[33] She is known for having a strong serve and powerful groundstrokes, which she uses to a hit a high number of winners.[25][26] Her forehand in particular is one of her best shots and was already very advanced while she was still a teenager.[15] CiCi Bellis faced Dolehide at the 2014 Orange Bowl when both players were still juniors and commented that Dolehide \"hits probably the hardest by far\" compared to Bellis\\'s other opponents and said \"her serve is amazing.\"[10] Venus Williams defeated Dolehide at the 2018 Canadian Open, but commented that \"she had a really great second serve.\"[34]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playing_style[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9da68",
   "metadata": {},
   "source": [
    "## 4. tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159c0ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 103player style txt and 1000 terms.\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer parameters\n",
    "# TfidfVectorizer will help us to create tf-idf matrix\n",
    "# max_df : maximum document frequency for the given word\n",
    "# min_df : minimum document frequency for the given word\n",
    "# max_features: maximum number of words\n",
    "# use_idf: if not true, we only calculate tf\n",
    "# stop_words : built-in stop words\n",
    "# tokenizer: how to tokenize the document\n",
    "# ngram_range: (min_value, max_value), eg. (1, 3) means the result will include 1-gram, 2-gram, 3-gram\n",
    "\n",
    "#tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "#                                 min_df=0.01, stop_words='english',\n",
    "#                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(2,3))\n",
    "\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_lemmatization, ngram_range=(2,3))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(playing_style) #fit the vectorizer to synopses\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \"player style txt and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9357696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ability hit',\n",
       " 'ability slide',\n",
       " 'able hit',\n",
       " 'able hit winner',\n",
       " 'accumulates significant',\n",
       " 'accumulates significant number',\n",
       " 'accurate groundstrokes',\n",
       " 'accurate serve',\n",
       " 'ace count',\n",
       " 'ace dictate',\n",
       " 'ace dictate stroke',\n",
       " 'ace frequently',\n",
       " 'ace match',\n",
       " 'ace serve',\n",
       " 'add reliable',\n",
       " 'add reliable source',\n",
       " 'adept hit',\n",
       " 'adept hit backhand',\n",
       " 'adept net',\n",
       " 'aggression score',\n",
       " 'aggressive baseline',\n",
       " 'aggressive baseliner',\n",
       " 'aggressive baseliner center',\n",
       " 'aggressive mindset',\n",
       " 'aggressive play',\n",
       " 'aggressive player',\n",
       " 'aggressive playing',\n",
       " 'aggressive return',\n",
       " 'aggressive return serve',\n",
       " 'aggressive shot',\n",
       " 'agnieszka radwańska',\n",
       " 'aid point',\n",
       " 'aid point construction',\n",
       " 'aim point',\n",
       " 'allow dictate',\n",
       " 'allow dominate',\n",
       " 'allow execute',\n",
       " 'allow generate',\n",
       " 'allow hit',\n",
       " 'allow hit winner',\n",
       " 'allow serve',\n",
       " 'allow serve ace',\n",
       " 'allow serve multiple',\n",
       " 'allow serve numerous',\n",
       " 'angelique kerber',\n",
       " 'angle forehand',\n",
       " 'angle forehand backhand',\n",
       " 'apply slice',\n",
       " 'apply slice backhand',\n",
       " 'approach net',\n",
       " 'approach net point',\n",
       " 'ashleigh barty',\n",
       " 'attack net',\n",
       " 'attack second',\n",
       " 'attack short',\n",
       " 'attack weak',\n",
       " 'attack weak second',\n",
       " 'average forehand',\n",
       " 'average mph',\n",
       " 'average mph allow',\n",
       " 'backhand allow',\n",
       " 'backhand best',\n",
       " 'backhand flat',\n",
       " 'backhand forehand',\n",
       " 'backhand hit',\n",
       " 'backhand hit flat',\n",
       " 'backhand hit winner',\n",
       " 'backhand line',\n",
       " 'backhand make',\n",
       " 'backhand particularly',\n",
       " 'backhand serve',\n",
       " 'backhand shot',\n",
       " 'backhand slice',\n",
       " 'backhand speed',\n",
       " 'backhand strong',\n",
       " 'backhand use',\n",
       " 'backhand winner',\n",
       " 'baseline allow',\n",
       " 'baseline forehand',\n",
       " 'baseline posse',\n",
       " 'baseline rally',\n",
       " 'baseliner center',\n",
       " 'baseliner center powerful',\n",
       " 'baseliner know',\n",
       " 'baseliner powerful',\n",
       " 'best returners',\n",
       " 'best shot',\n",
       " 'best shot forehand',\n",
       " 'big asset',\n",
       " 'big serve',\n",
       " 'big weapon',\n",
       " 'biography live',\n",
       " 'biography live person',\n",
       " 'bold large',\n",
       " 'bold large color',\n",
       " 'book scholar',\n",
       " 'book scholar jstor',\n",
       " 'border border',\n",
       " 'border border center',\n",
       " 'border center']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words\n",
    "tf_selected_words = tfidf_model.get_feature_names()\n",
    "tf_selected_words[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a94d2",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e0316b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(46)\n",
    "# Use LDA for clustering， 7 topics （7 classes of players), tried 8 topics 2 of which are highly similar \n",
    "# to each other\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=4, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20e31645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 4)\n",
      "[[0.04772266 0.85453048 0.04976674 0.04798011]\n",
      " [0.02314252 0.0284118  0.92534888 0.02309681]\n",
      " [0.02424711 0.92753317 0.02417146 0.02404826]\n",
      " [0.01832626 0.94496344 0.01840447 0.01830583]\n",
      " [0.03332912 0.33882153 0.5958206  0.03202875]\n",
      " [0.08449208 0.0866183  0.74277829 0.08611133]\n",
      " [0.05096612 0.84754504 0.0507183  0.05077054]\n",
      " [0.03096579 0.43518749 0.50234109 0.03150562]\n",
      " [0.0225192  0.93230878 0.02280357 0.02236845]\n",
      " [0.8607786  0.04799141 0.04587847 0.04535152]\n",
      " [0.06677332 0.06970195 0.06699843 0.7965263 ]\n",
      " [0.05503192 0.05600472 0.05550663 0.83345673]\n",
      " [0.12509904 0.12723782 0.12716241 0.62050073]\n",
      " [0.68562492 0.10649279 0.10418343 0.10369887]\n",
      " [0.06144094 0.06388098 0.81292731 0.06175077]\n",
      " [0.04701713 0.0522004  0.85398092 0.04680156]\n",
      " [0.79543964 0.07019192 0.06685914 0.0675093 ]\n",
      " [0.02015432 0.93955416 0.02027746 0.02001406]\n",
      " [0.01950245 0.94163873 0.01949083 0.01936799]\n",
      " [0.03428553 0.2140449  0.71796146 0.03370811]\n",
      " [0.05717938 0.06064293 0.8245717  0.05760599]\n",
      " [0.05036173 0.05197753 0.05163678 0.84602396]\n",
      " [0.07057536 0.07407597 0.78449179 0.07085687]\n",
      " [0.02150624 0.93532676 0.02162945 0.02153755]\n",
      " [0.02917635 0.91241645 0.02931021 0.02909698]\n",
      " [0.02726707 0.91797602 0.02754763 0.02720929]\n",
      " [0.7214707  0.09333272 0.09238433 0.09281224]\n",
      " [0.02275572 0.93189905 0.02282617 0.02251906]\n",
      " [0.05307217 0.84100437 0.05322008 0.05270338]\n",
      " [0.06704846 0.79879701 0.06774546 0.06640906]\n",
      " [0.86439944 0.04749468 0.04394214 0.04416373]\n",
      " [0.0268756  0.9191293  0.0272641  0.026731  ]\n",
      " [0.02607623 0.92092187 0.02658643 0.02641546]\n",
      " [0.05948784 0.07296682 0.06123652 0.80630881]\n",
      " [0.01997158 0.94016486 0.02001931 0.01984425]\n",
      " [0.07931502 0.75585036 0.07945839 0.08537623]\n",
      " [0.06310072 0.06389579 0.06220796 0.81079553]\n",
      " [0.0278416  0.91664276 0.02793565 0.02757999]\n",
      " [0.03790153 0.03829723 0.88547942 0.03832182]\n",
      " [0.03855854 0.88781552 0.0367554  0.03687054]\n",
      " [0.03541312 0.8849715  0.04523128 0.0343841 ]\n",
      " [0.03879704 0.88436128 0.03843288 0.03840881]\n",
      " [0.059674   0.06098581 0.05992701 0.81941318]\n",
      " [0.04785003 0.85500273 0.04805425 0.04909299]\n",
      " [0.02249573 0.93251288 0.02247825 0.02251314]\n",
      " [0.02429892 0.92686245 0.02436709 0.02447154]\n",
      " [0.02523998 0.92312331 0.02614342 0.02549328]\n",
      " [0.03738459 0.71073937 0.21442337 0.03745267]\n",
      " [0.02763708 0.91694236 0.02770075 0.02771981]\n",
      " [0.06774841 0.79874888 0.06739663 0.06610608]\n",
      " [0.05202523 0.05197685 0.84454064 0.05145728]\n",
      " [0.03021189 0.90885803 0.03058573 0.03034435]\n",
      " [0.0608862  0.81189617 0.06677204 0.06044559]\n",
      " [0.25       0.25       0.25       0.25      ]\n",
      " [0.05220172 0.05530779 0.838449   0.05404149]\n",
      " [0.02421758 0.92828904 0.02379033 0.02370304]\n",
      " [0.05581393 0.05716356 0.83167044 0.05535207]\n",
      " [0.05672908 0.83213187 0.0555831  0.05555595]\n",
      " [0.03877597 0.88009408 0.04110499 0.04002496]\n",
      " [0.03864781 0.88422396 0.03852237 0.03860586]\n",
      " [0.03302532 0.90179062 0.03279237 0.0323917 ]\n",
      " [0.02545481 0.92339749 0.02567659 0.02547112]\n",
      " [0.07032272 0.07404361 0.07172033 0.78391335]\n",
      " [0.04038384 0.87920046 0.04081032 0.03960538]\n",
      " [0.02963806 0.91056154 0.03024429 0.0295561 ]\n",
      " [0.84125557 0.0534519  0.05285991 0.05243262]\n",
      " [0.6775757  0.24057582 0.0413042  0.04054428]\n",
      " [0.09363374 0.7151566  0.09611857 0.09509109]\n",
      " [0.07452719 0.07495284 0.77722928 0.07329069]\n",
      " [0.03002693 0.03038328 0.90957529 0.0300145 ]\n",
      " [0.04986526 0.05220578 0.84844683 0.04948214]\n",
      " [0.03073829 0.03372891 0.90503948 0.03049332]\n",
      " [0.02437577 0.36545857 0.58621075 0.02395491]\n",
      " [0.828488   0.0576195  0.05760966 0.05628284]\n",
      " [0.09354691 0.71853394 0.09451788 0.09340127]\n",
      " [0.86676246 0.04769224 0.04262332 0.04292198]\n",
      " [0.03963846 0.8823481  0.0394388  0.03857464]\n",
      " [0.02834739 0.91692666 0.02741445 0.0273115 ]\n",
      " [0.8430984  0.05470836 0.05111643 0.05107681]\n",
      " [0.04210571 0.87248794 0.04310001 0.04230634]\n",
      " [0.73482948 0.20783762 0.02819622 0.02913668]\n",
      " [0.04425968 0.86651324 0.04472128 0.04450581]\n",
      " [0.06245369 0.0647862  0.81022666 0.06253345]\n",
      " [0.02552222 0.92342904 0.02565778 0.02539096]\n",
      " [0.04206252 0.87091484 0.04391127 0.04311137]\n",
      " [0.0341035  0.89895288 0.03366223 0.03328139]\n",
      " [0.06469158 0.07007218 0.06805624 0.79717999]\n",
      " [0.03228315 0.03983411 0.0314342  0.89644854]\n",
      " [0.04213421 0.87443958 0.04177263 0.04165357]\n",
      " [0.05645272 0.83134558 0.05670239 0.05549931]\n",
      " [0.03843334 0.88589854 0.03816109 0.03750703]\n",
      " [0.54556461 0.39230342 0.03119237 0.03093959]\n",
      " [0.04466394 0.86552104 0.0442119  0.04560312]\n",
      " [0.06381725 0.06802853 0.80449457 0.06365965]\n",
      " [0.04313588 0.87189219 0.04250067 0.04247127]\n",
      " [0.81645246 0.06239135 0.06079506 0.06036113]\n",
      " [0.02479033 0.92494881 0.02505161 0.02520925]\n",
      " [0.03273106 0.89274712 0.04188872 0.0326331 ]\n",
      " [0.0537001  0.83774088 0.05448807 0.05407095]\n",
      " [0.06309563 0.06519577 0.80759058 0.06411803]\n",
      " [0.04340164 0.86994525 0.04403923 0.04261387]\n",
      " [0.04170259 0.65017769 0.26686501 0.0412547 ]\n",
      " [0.02226001 0.93344631 0.02229264 0.02200103]]\n"
     ]
    }
   ],
   "source": [
    "# document topic matrix for tfidf_matrix_lda\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "print(lda_output.shape)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0384e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1000)\n",
      "[[0.14285769 0.14285827 0.56265655 ... 0.34572279 0.34572279 0.46924618]\n",
      " [0.14285782 0.23892403 0.14285803 ... 0.14295117 0.14295117 0.14285807]\n",
      " [0.14285783 0.14285857 0.14304798 ... 0.14290226 0.14290226 0.14285807]\n",
      " ...\n",
      " [0.14325037 0.34313581 0.14285795 ... 0.43426677 0.43426677 0.14285798]\n",
      " [0.28132811 0.23591786 0.39064477 ... 0.6951197  0.6951197  0.38868884]\n",
      " [0.53915536 0.14982252 0.61220423 ... 0.96407009 0.96407009 0.14285782]]\n"
     ]
    }
   ],
   "source": [
    "# topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word.shape)\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b17dd236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Caroline Dolehide</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donna Vekic</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caroline Wozniacki</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbora Krejcikova</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kristina Mladenovic</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yaroslava Shvedova</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco Vandeweghe</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Petra Kvitova</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elise Mertens</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anastasija Sevastova</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  \\\n",
       "Caroline Dolehide       0.83    0.03    0.03    0.03    0.03    0.03    0.03   \n",
       "Donna Vekic             0.76    0.01    0.01    0.01    0.01    0.01    0.18   \n",
       "Caroline Wozniacki      0.01    0.01    0.01    0.01    0.01    0.01    0.91   \n",
       "Barbora Krejcikova      0.53    0.01    0.01    0.01    0.01    0.01    0.42   \n",
       "Kristina Mladenovic     0.02    0.02    0.02    0.02    0.02    0.02    0.89   \n",
       "Yaroslava Shvedova      0.05    0.05    0.71    0.05    0.05    0.05    0.05   \n",
       "Coco Vandeweghe         0.03    0.03    0.03    0.83    0.03    0.03    0.03   \n",
       "Petra Kvitova           0.02    0.02    0.02    0.02    0.89    0.02    0.02   \n",
       "Elise Mertens           0.01    0.01    0.01    0.01    0.92    0.01    0.01   \n",
       "Anastasija Sevastova    0.86    0.02    0.02    0.02    0.02    0.02    0.02   \n",
       "\n",
       "                      topic  \n",
       "Caroline Dolehide         0  \n",
       "Donna Vekic               0  \n",
       "Caroline Wozniacki        6  \n",
       "Barbora Krejcikova        0  \n",
       "Kristina Mladenovic       6  \n",
       "Yaroslava Shvedova        2  \n",
       "Coco Vandeweghe           3  \n",
       "Petra Kvitova             4  \n",
       "Elise Mertens             4  \n",
       "Anastasija Sevastova      0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "\n",
    "# index names\n",
    "name1 = [ \" \".join(n.split(\".\")[:-1]) for n in name]\n",
    "doc_names = [name1[i] for i in range(len(playing_style))]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "\n",
    "\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14ad3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic.to_csv(\"/Users/liuyiwu/540/project/f_document_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3146f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic\n",
       "18     15\n",
       "6       7\n",
       "11      6\n",
       "10      4\n",
       "9       4\n",
       "4       4\n",
       "12      4\n",
       "29      4\n",
       "7       4\n",
       "2       4\n",
       "16      4\n",
       "8       4\n",
       "13      3\n",
       "17      3\n",
       "28      3\n",
       "0       3\n",
       "20      3\n",
       "22      3\n",
       "14      3\n",
       "5       3\n",
       "25      2\n",
       "24      2\n",
       "3       2\n",
       "27      2\n",
       "21      2\n",
       "19      1\n",
       "23      1\n",
       "26      1\n",
       "1       1\n",
       "15      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6ebcc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability hit</th>\n",
       "      <th>ability slide</th>\n",
       "      <th>able hit</th>\n",
       "      <th>able hit winner</th>\n",
       "      <th>accumulates significant</th>\n",
       "      <th>accumulates significant number</th>\n",
       "      <th>accurate groundstrokes</th>\n",
       "      <th>accurate serve</th>\n",
       "      <th>ace count</th>\n",
       "      <th>ace dictate</th>\n",
       "      <th>...</th>\n",
       "      <th>winner point</th>\n",
       "      <th>winner position</th>\n",
       "      <th>winner position forehand</th>\n",
       "      <th>winner possess</th>\n",
       "      <th>winner shoot</th>\n",
       "      <th>winner shot</th>\n",
       "      <th>winner typically</th>\n",
       "      <th>winner unforced</th>\n",
       "      <th>winner unforced error</th>\n",
       "      <th>work early</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ability hit  ability slide  able hit  able hit winner  \\\n",
       "Topic0         0.14           0.14      0.56             0.57   \n",
       "Topic1         0.14           0.24      0.14             0.14   \n",
       "Topic2         0.14           0.14      0.14             0.14   \n",
       "Topic3         0.14           0.14      0.14             0.14   \n",
       "Topic4         0.14           0.34      0.14             0.14   \n",
       "Topic5         0.28           0.24      0.39             0.14   \n",
       "Topic6         0.54           0.15      0.61             0.28   \n",
       "\n",
       "        accumulates significant  accumulates significant number  \\\n",
       "Topic0                     0.27                            0.27   \n",
       "Topic1                     0.14                            0.14   \n",
       "Topic2                     0.14                            0.14   \n",
       "Topic3                     0.14                            0.14   \n",
       "Topic4                     0.14                            0.14   \n",
       "Topic5                     0.14                            0.14   \n",
       "Topic6                     0.35                            0.35   \n",
       "\n",
       "        accurate groundstrokes  accurate serve  ace count  ace dictate  ...  \\\n",
       "Topic0                    0.36            0.34       0.38         0.27  ...   \n",
       "Topic1                    0.14            0.14       0.14         0.14  ...   \n",
       "Topic2                    0.14            0.26       0.14         0.14  ...   \n",
       "Topic3                    0.14            0.14       0.14         0.14  ...   \n",
       "Topic4                    0.14            0.33       0.24         0.23  ...   \n",
       "Topic5                    0.68            0.39       0.31         0.14  ...   \n",
       "Topic6                    0.14            0.14       0.23         0.66  ...   \n",
       "\n",
       "        winner point  winner position  winner position forehand  \\\n",
       "Topic0          0.36             0.46                      0.14   \n",
       "Topic1          0.14             0.34                      0.14   \n",
       "Topic2          0.14             0.23                      0.14   \n",
       "Topic3          0.14             0.14                      0.14   \n",
       "Topic4          0.14             0.22                      0.14   \n",
       "Topic5          0.28             0.35                      0.24   \n",
       "Topic6          0.14             0.39                      0.28   \n",
       "\n",
       "        winner possess  winner shoot  winner shot  winner typically  \\\n",
       "Topic0            0.14          0.14         0.29              0.28   \n",
       "Topic1            0.14          0.14         0.14              0.14   \n",
       "Topic2            0.14          0.27         0.14              0.14   \n",
       "Topic3            0.14          0.14         0.14              0.14   \n",
       "Topic4            0.29          0.14         0.15              0.14   \n",
       "Topic5            0.14          0.24         0.31              0.32   \n",
       "Topic6            0.44          0.14         0.38              0.14   \n",
       "\n",
       "        winner unforced  winner unforced error  work early  \n",
       "Topic0             0.35                   0.35        0.47  \n",
       "Topic1             0.14                   0.14        0.14  \n",
       "Topic2             0.14                   0.14        0.14  \n",
       "Topic3             0.14                   0.14        0.14  \n",
       "Topic4             0.43                   0.43        0.14  \n",
       "Topic5             0.70                   0.70        0.39  \n",
       "Topic6             0.96                   0.96        0.14  \n",
       "\n",
       "[7 rows x 1000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic-word matrix\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# column and index\n",
    "df_topic_words.columns = tfidf_model.get_feature_names()\n",
    "df_topic_words.index = topic_names\n",
    "\n",
    "df_topic_words = df_topic_words.round(2)\n",
    "df_topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3b3d4",
   "metadata": {},
   "source": [
    "here we get the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "119c43bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Word 15</th>\n",
       "      <th>Word 16</th>\n",
       "      <th>Word 17</th>\n",
       "      <th>Word 18</th>\n",
       "      <th>Word 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>play style</td>\n",
       "      <td>forehand hit</td>\n",
       "      <td>drop shot</td>\n",
       "      <td>backhand forehand</td>\n",
       "      <td>hit ball</td>\n",
       "      <td>return game</td>\n",
       "      <td>big asset</td>\n",
       "      <td>win point</td>\n",
       "      <td>monica seles</td>\n",
       "      <td>style play</td>\n",
       "      <td>shot play</td>\n",
       "      <td>hard court</td>\n",
       "      <td>main weakness</td>\n",
       "      <td>favorite surface</td>\n",
       "      <td>accurate groundstrokes</td>\n",
       "      <td>break opponent</td>\n",
       "      <td>backhand line</td>\n",
       "      <td>percentage return</td>\n",
       "      <td>point return</td>\n",
       "      <td>play play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>hit winner</td>\n",
       "      <td>second serve</td>\n",
       "      <td>unforced error</td>\n",
       "      <td>forehand backhand</td>\n",
       "      <td>double fault</td>\n",
       "      <td>powerful groundstrokes</td>\n",
       "      <td>wta tour</td>\n",
       "      <td>style play</td>\n",
       "      <td>backhand slice</td>\n",
       "      <td>hard court</td>\n",
       "      <td>grass court</td>\n",
       "      <td>playing style</td>\n",
       "      <td>serve ace</td>\n",
       "      <td>drop shot</td>\n",
       "      <td>allow serve</td>\n",
       "      <td>french open</td>\n",
       "      <td>mph allow</td>\n",
       "      <td>sharp angle</td>\n",
       "      <td>mph allow serve</td>\n",
       "      <td>winner unforced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>solid solid</td>\n",
       "      <td>style play</td>\n",
       "      <td>solid solid solid</td>\n",
       "      <td>high number</td>\n",
       "      <td>drop shot</td>\n",
       "      <td>powerful forehand use</td>\n",
       "      <td>second round</td>\n",
       "      <td>unforced error</td>\n",
       "      <td>use forehand</td>\n",
       "      <td>produce high number</td>\n",
       "      <td>aggressive style play</td>\n",
       "      <td>produce high</td>\n",
       "      <td>serve forehand</td>\n",
       "      <td>u open</td>\n",
       "      <td>powerful serve</td>\n",
       "      <td>aggressive style</td>\n",
       "      <td>powerful forehand</td>\n",
       "      <td>play match</td>\n",
       "      <td>high number winner</td>\n",
       "      <td>long rally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>play backhand</td>\n",
       "      <td>speed court</td>\n",
       "      <td>match wimbledon</td>\n",
       "      <td>topspin forehand</td>\n",
       "      <td>surface clay</td>\n",
       "      <td>primary strength</td>\n",
       "      <td>note powerful</td>\n",
       "      <td>game great</td>\n",
       "      <td>female player</td>\n",
       "      <td>prefer surface</td>\n",
       "      <td>posse high topspin</td>\n",
       "      <td>posse high</td>\n",
       "      <td>serve able</td>\n",
       "      <td>know fast</td>\n",
       "      <td>clay surface</td>\n",
       "      <td>justine henin</td>\n",
       "      <td>shot backhand</td>\n",
       "      <td>title clay</td>\n",
       "      <td>powerful forehand</td>\n",
       "      <td>return serf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word 0        Word 1             Word 2             Word 3  \\\n",
       "Topic 0     play style  forehand hit          drop shot  backhand forehand   \n",
       "Topic 1     hit winner  second serve     unforced error  forehand backhand   \n",
       "Topic 2    solid solid    style play  solid solid solid        high number   \n",
       "Topic 3  play backhand   speed court    match wimbledon   topspin forehand   \n",
       "\n",
       "               Word 4                  Word 5         Word 6          Word 7  \\\n",
       "Topic 0      hit ball             return game      big asset       win point   \n",
       "Topic 1  double fault  powerful groundstrokes       wta tour      style play   \n",
       "Topic 2     drop shot   powerful forehand use   second round  unforced error   \n",
       "Topic 3  surface clay        primary strength  note powerful      game great   \n",
       "\n",
       "                 Word 8               Word 9                Word 10  \\\n",
       "Topic 0    monica seles           style play              shot play   \n",
       "Topic 1  backhand slice           hard court            grass court   \n",
       "Topic 2    use forehand  produce high number  aggressive style play   \n",
       "Topic 3   female player       prefer surface     posse high topspin   \n",
       "\n",
       "               Word 11         Word 12           Word 13  \\\n",
       "Topic 0     hard court   main weakness  favorite surface   \n",
       "Topic 1  playing style       serve ace         drop shot   \n",
       "Topic 2   produce high  serve forehand            u open   \n",
       "Topic 3     posse high      serve able         know fast   \n",
       "\n",
       "                        Word 14           Word 15            Word 16  \\\n",
       "Topic 0  accurate groundstrokes    break opponent      backhand line   \n",
       "Topic 1             allow serve       french open          mph allow   \n",
       "Topic 2          powerful serve  aggressive style  powerful forehand   \n",
       "Topic 3            clay surface     justine henin      shot backhand   \n",
       "\n",
       "                   Word 17             Word 18          Word 19  \n",
       "Topic 0  percentage return        point return        play play  \n",
       "Topic 1        sharp angle     mph allow serve  winner unforced  \n",
       "Topic 2         play match  high number winner       long rally  \n",
       "Topic 3         title clay   powerful forehand      return serf  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=20)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e46a85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### classify players into 8 style groups based on 5 types of features\n",
    "### 1. Aggresive/Defensive/natural  2.Court preference (4 types)   3. Backhand/fronthand/both  4.hit hard/weak\n",
    "style_dic = {}\n",
    "style_dic[\"Topic0\"] = [\"balanced\", \"no\", \"backhand\", \"powerful\"]\n",
    "style_dic[\"Topic1\"] = [\"balanced\", \"hard\", \"both\", \"powerful\"]\n",
    "style_dic[\"Topic2\"] = [\"aggressive\", \"grass or hard\", \"both\", \"weak\"]\n",
    "style_dic[\"Topic3\"] = [\"aggresive\", \"no\", \"both\", \"hard\"]\n",
    "style_dic[\"Topic4\"] = [\"aggresive\", \"grass\", \"both\", \"hard\"]\n",
    "### similar features \"approach net\" and \"aggresive\"\n",
    "style_dic[\"Topic5\"] = [\"balanced\", \"no\", \"both\", \"hard\"]\n",
    "### waiting for opportunity = defensive\n",
    "style_dic[\"Topic6\"] = [\"defensive\", \"grass and clay\", \"backhand\", \"hard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e563e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 7\n",
    "\n",
    "# number of clusters\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "796a9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = {'players': doc_names, 'cluster': clusters}\n",
    "frame = pd.DataFrame(product, columns = ['players', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "741ffddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caroline Dolehide</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donna Vekic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caroline Wozniacki</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barbora Krejcikova</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristina Mladenovic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yaroslava Shvedova</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Coco Vandeweghe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Petra Kvitova</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elise Mertens</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anastasija Sevastova</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                players  cluster\n",
       "0     Caroline Dolehide        5\n",
       "1           Donna Vekic        2\n",
       "2    Caroline Wozniacki        5\n",
       "3    Barbora Krejcikova        1\n",
       "4   Kristina Mladenovic        3\n",
       "5    Yaroslava Shvedova        5\n",
       "6       Coco Vandeweghe        5\n",
       "7         Petra Kvitova        6\n",
       "8         Elise Mertens        0\n",
       "9  Anastasija Sevastova        4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "767bcedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews included in each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "1       29\n",
       "0       22\n",
       "5       19\n",
       "3       11\n",
       "4       11\n",
       "6        6\n",
       "2        5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Number of reviews included in each cluster:\")\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fb05bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words:backhand slice,unforced error,hit winner,allow serve,peak mph,average mph,mph allow,second serve,serve ace,mph allow serve,hit backhand,double experience,posse effective,hard court,forehand backhand,\n",
      "Cluster 0 players (22 players): \n",
      "\n",
      "Cluster 1 words:double fault,unforced error,hit winner,second serve,allow hit,serve abbreviate,winner unforced,winner unforced error,serve lack,offensive baseliner,powerful forehand,win match,long rally,backhand forehand,aggressive playing,\n",
      "Cluster 1 players (29 players): \n",
      "\n",
      "Cluster 2 words:forehand hit,center border,border center border,border center,remove message,learn remove message,learn remove,hidden collapse border,medium section,center border important,center border center,border important medium,border important,fbfbfb html,collapse border border,\n",
      "Cluster 2 players (5 players): \n",
      "\n",
      "Cluster 3 words:drop shot,slice drop shot,slice drop,backhand line,hit slice,strength serve,shot develop,play clay,hard hit,big asset,slice forehand,shot backhand,favourite shot,slice backhand,serve quickness,\n",
      "Cluster 3 players (11 players): \n",
      "\n",
      "Cluster 4 words:forehand backhand,play backhand,sharp angle,accurate groundstrokes,power hit,produce winner,hit hard,return shot,baseliner powerful,use hand,extend rally,shot hit,potent weapon,groundstrokes forehand,aggressive baseliner,\n",
      "Cluster 4 players (11 players): \n",
      "\n",
      "Cluster 5 words:shot forehand,play backhand,note powerful,justine henin,variety shot,grass court,preferred surface,grand slam,best shot,surface grass,second serve,best shot forehand,aggressive baseliner,powerful serve,play aggressively,\n",
      "Cluster 5 players (19 players): \n",
      "\n",
      "Cluster 6 words:know fast,strong serve,service game,important important,wing make,wing make hard,serve able,enjoy play,unforced error,display block,roman serif bold,roman serif,bold large color,color gray content,large color gray,\n",
      "Cluster 6 players (6 players): \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#km.cluster_centers_ denotes the importances of each items in centroid.\n",
    "#We need to sort it in decreasing-order and get the top k items.\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "Cluster_keywords_summary = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
    "    Cluster_keywords_summary[i] = []\n",
    "    for ind in order_centroids[i, :15]: #replace 6 with n words per cluster\n",
    "        Cluster_keywords_summary[i].append(tf_selected_words[ind])\n",
    "        print (tf_selected_words[ind] + \",\", end='')\n",
    "    print()\n",
    "  \n",
    "    cluster_reviews = frame[frame.cluster==i].players.tolist()\n",
    "    print (\"Cluster \" + str(i) + \" players (\" + str(len(cluster_reviews)) + \" players): \")\n",
    "    #print (\", \".join(cluster_reviews))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3a11a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "### new stopwords selected based on frequency in the corpus\n",
    "new_stopwords = ['serv','play','court','game','also','player','style','use','ball',\n",
    "                 'allow','tour','describ','although','time','howev','wta','atp','note',\n",
    "                 'consid','career','finish','year','need','prefer','said','take','number',\n",
    "                 'employ','come','despit','skill','set','lot','record','result','could','comment',\n",
    "                 'except','made','includ','sinc','per','somtim','amount','develop','extrem','even',\n",
    "                 'bank','work','australian','feel','regard','favorit','world','among','much','instead',\n",
    "                 'hour','em','whose','think','later','put','would','women','help','though','way','american',\n",
    "                 'interview','alway','ever','look','she','almost','peopl','server','place','refer','problem',\n",
    "                 'either','rather','keep','away','still','enough','someth','thing','john','kvitová','toward',\n",
    "                 'see','util','build','began','level','unlike','mayb','solid','template', 'citation', \n",
    "                 'percentage', 'surface', 'us', 'french', 'open', 'serena', 'weakness', 'venus', 'wimbledon']\n",
    "\n",
    "for i in new_stopwords:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3280bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "170e7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 103player style txt and 1000 terms.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_lemmatization, ngram_range=(2,3))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(playing_style) #fit the vectorizer to synopses\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \"player style txt and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e2182bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf scores: \n",
      " [('style play', 3.9673124945590317), ('unforced error', 3.4270441250778974), ('hit winner', 3.361322200283284), ('drop shot', 3.217677534671646), ('forehand backhand', 3.2085044742828264), ('second serve', 3.0373871094395013), ('play backhand', 2.8638572882871047), ('double fault', 2.5801053069663866), ('hit ball', 2.4273950510334377), ('hard court', 2.387781236108507), ('backhand slice', 2.1290214289715887), ('wta tour', 2.088563278448431), ('playing style', 2.0784453947955797), ('aggressive style', 2.065910919834918), ('play style', 1.9875569752513937), ('powerful groundstrokes', 1.9763381661142436), ('finish point', 1.9756870953190124), ('favourite surface', 1.928883695919309), ('french open', 1.9244568988506898), ('forehand hit', 1.924233688687468), ('powerful serve', 1.8841741911408858), ('grass court', 1.849153478384462), ('powerful forehand', 1.8345176521111484), ('hit flat', 1.8209713410996486), ('grand slam', 1.7565203488539984), ('number winner', 1.7241202761559278), ('winner unforced', 1.7221921594550698), ('winner unforced error', 1.7221921594550698), ('aggressive baseliner', 1.709723345667596), ('serve ace', 1.6651738349755636), ('speed court', 1.6563195574112104), ('aggressive style play', 1.6215170488816093), ('u open', 1.6213019674008822), ('sharp angle', 1.6177931110209474), ('surface clay', 1.597495210615216), ('high number', 1.5895466093659127), ('shot forehand', 1.5725661987652915), ('allow serve', 1.5619902302158875), ('solid solid', 1.5583131241248283), ('win point', 1.5578720179188232), ('approach net', 1.5477785514460534), ('capable hit', 1.5267756326845001), ('clay court', 1.5239876648164592), ('main weakness', 1.5163160130247502), ('mph allow', 1.5147995173883633), ('strong serve', 1.5116714536789881), ('aggressive player', 1.4821290282577382), ('enjoy play', 1.465279965870772), ('citation need', 1.4650150621109481), ('mph allow serve', 1.4633893222187875)]\n"
     ]
    }
   ],
   "source": [
    "tf_selected_words = tfidf_model.get_feature_names()\n",
    "\n",
    "X = tfidf_model.fit_transform(playing_style)\n",
    "\n",
    "top_n = 50\n",
    "print('tf_idf scores: \\n', sorted(list(zip(tfidf_model.get_feature_names(), \n",
    "                                             X.sum(0).getA1())), \n",
    "                                 key=lambda x: x[1], reverse=True)[:top_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1462880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Word 15</th>\n",
       "      <th>Word 16</th>\n",
       "      <th>Word 17</th>\n",
       "      <th>Word 18</th>\n",
       "      <th>Word 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>double fault</td>\n",
       "      <td>hit winner</td>\n",
       "      <td>second serve</td>\n",
       "      <td>forehand backhand</td>\n",
       "      <td>serve ace</td>\n",
       "      <td>unforced error</td>\n",
       "      <td>allow serve</td>\n",
       "      <td>mph allow</td>\n",
       "      <td>backhand slice</td>\n",
       "      <td>mph allow serve</td>\n",
       "      <td>peak mph</td>\n",
       "      <td>playing style</td>\n",
       "      <td>winner unforced</td>\n",
       "      <td>winner unforced error</td>\n",
       "      <td>average mph</td>\n",
       "      <td>double experience</td>\n",
       "      <td>wta tour</td>\n",
       "      <td>allow serve ace</td>\n",
       "      <td>create opportunity</td>\n",
       "      <td>drop shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>solid solid</td>\n",
       "      <td>play backhand</td>\n",
       "      <td>solid solid solid</td>\n",
       "      <td>shot backhand</td>\n",
       "      <td>powerful serve groundstrokes</td>\n",
       "      <td>clay court</td>\n",
       "      <td>unforced error</td>\n",
       "      <td>net play</td>\n",
       "      <td>flat groundstrokes</td>\n",
       "      <td>aggressive baseliner</td>\n",
       "      <td>female player</td>\n",
       "      <td>groundstrokes hit</td>\n",
       "      <td>volley skill</td>\n",
       "      <td>favourite shot</td>\n",
       "      <td>hit shot</td>\n",
       "      <td>hit powerful</td>\n",
       "      <td>serve major</td>\n",
       "      <td>note powerful</td>\n",
       "      <td>center border</td>\n",
       "      <td>border center border</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>clean winner</td>\n",
       "      <td>monica seles</td>\n",
       "      <td>french open</td>\n",
       "      <td>service game</td>\n",
       "      <td>backhand forehand</td>\n",
       "      <td>shot forehand</td>\n",
       "      <td>play backhand</td>\n",
       "      <td>create sharp</td>\n",
       "      <td>create sharp angle</td>\n",
       "      <td>main weakness</td>\n",
       "      <td>come net</td>\n",
       "      <td>style play</td>\n",
       "      <td>martina hingis</td>\n",
       "      <td>capable hit</td>\n",
       "      <td>nigel sears</td>\n",
       "      <td>offensive baseliner</td>\n",
       "      <td>sharp angle</td>\n",
       "      <td>game base</td>\n",
       "      <td>martina navratilova</td>\n",
       "      <td>tennis player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>style play</td>\n",
       "      <td>hit slice</td>\n",
       "      <td>aggressive style play</td>\n",
       "      <td>drop shot</td>\n",
       "      <td>aggressive style</td>\n",
       "      <td>best surface</td>\n",
       "      <td>slice drop</td>\n",
       "      <td>slice drop shot</td>\n",
       "      <td>strength serve</td>\n",
       "      <td>petra kvitová</td>\n",
       "      <td>hard court</td>\n",
       "      <td>play clay</td>\n",
       "      <td>main weakness</td>\n",
       "      <td>backhand line</td>\n",
       "      <td>shot hit</td>\n",
       "      <td>lot ball</td>\n",
       "      <td>ball play</td>\n",
       "      <td>aggressive player</td>\n",
       "      <td>point player</td>\n",
       "      <td>court title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>forehand hit</td>\n",
       "      <td>play style</td>\n",
       "      <td>drop shot</td>\n",
       "      <td>play surface</td>\n",
       "      <td>big asset</td>\n",
       "      <td>enjoy play</td>\n",
       "      <td>player use</td>\n",
       "      <td>baseline forehand</td>\n",
       "      <td>surface like</td>\n",
       "      <td>shot play</td>\n",
       "      <td>martina hingis</td>\n",
       "      <td>backhand line</td>\n",
       "      <td>favourite shot</td>\n",
       "      <td>style play</td>\n",
       "      <td>tennis like</td>\n",
       "      <td>prepare hit</td>\n",
       "      <td>break opponent</td>\n",
       "      <td>slice drop</td>\n",
       "      <td>slice drop shot</td>\n",
       "      <td>play tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>hit ball</td>\n",
       "      <td>style play</td>\n",
       "      <td>match wimbledon</td>\n",
       "      <td>note powerful</td>\n",
       "      <td>hard court</td>\n",
       "      <td>volley winner</td>\n",
       "      <td>play clay</td>\n",
       "      <td>grass hard court</td>\n",
       "      <td>aggressive style</td>\n",
       "      <td>really really</td>\n",
       "      <td>play backhand</td>\n",
       "      <td>play grass</td>\n",
       "      <td>clay court</td>\n",
       "      <td>grass hard</td>\n",
       "      <td>speed court</td>\n",
       "      <td>forehand backhand</td>\n",
       "      <td>backhand solid</td>\n",
       "      <td>primary strength</td>\n",
       "      <td>surface grass</td>\n",
       "      <td>kim clijsters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>mile hour</td>\n",
       "      <td>unforced error</td>\n",
       "      <td>allow hit</td>\n",
       "      <td>hit large</td>\n",
       "      <td>hit large number</td>\n",
       "      <td>number winner</td>\n",
       "      <td>strong forehand</td>\n",
       "      <td>serena williams</td>\n",
       "      <td>u open</td>\n",
       "      <td>large number winner</td>\n",
       "      <td>finish point</td>\n",
       "      <td>style play</td>\n",
       "      <td>win point</td>\n",
       "      <td>aggression score</td>\n",
       "      <td>grand slam</td>\n",
       "      <td>hard court</td>\n",
       "      <td>backhand serve</td>\n",
       "      <td>game style</td>\n",
       "      <td>rarely win</td>\n",
       "      <td>speed court</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word 0          Word 1                 Word 2  \\\n",
       "Topic 0  double fault      hit winner           second serve   \n",
       "Topic 1   solid solid   play backhand      solid solid solid   \n",
       "Topic 2  clean winner    monica seles            french open   \n",
       "Topic 3    style play       hit slice  aggressive style play   \n",
       "Topic 4  forehand hit      play style              drop shot   \n",
       "Topic 5      hit ball      style play        match wimbledon   \n",
       "Topic 6     mile hour  unforced error              allow hit   \n",
       "\n",
       "                    Word 3                        Word 4          Word 5  \\\n",
       "Topic 0  forehand backhand                     serve ace  unforced error   \n",
       "Topic 1      shot backhand  powerful serve groundstrokes      clay court   \n",
       "Topic 2       service game             backhand forehand   shot forehand   \n",
       "Topic 3          drop shot              aggressive style    best surface   \n",
       "Topic 4       play surface                     big asset      enjoy play   \n",
       "Topic 5      note powerful                    hard court   volley winner   \n",
       "Topic 6          hit large              hit large number   number winner   \n",
       "\n",
       "                  Word 6             Word 7              Word 8  \\\n",
       "Topic 0      allow serve          mph allow      backhand slice   \n",
       "Topic 1   unforced error           net play  flat groundstrokes   \n",
       "Topic 2    play backhand       create sharp  create sharp angle   \n",
       "Topic 3       slice drop    slice drop shot      strength serve   \n",
       "Topic 4       player use  baseline forehand        surface like   \n",
       "Topic 5        play clay   grass hard court    aggressive style   \n",
       "Topic 6  strong forehand    serena williams              u open   \n",
       "\n",
       "                       Word 9         Word 10            Word 11  \\\n",
       "Topic 0       mph allow serve        peak mph      playing style   \n",
       "Topic 1  aggressive baseliner   female player  groundstrokes hit   \n",
       "Topic 2         main weakness        come net         style play   \n",
       "Topic 3         petra kvitová      hard court          play clay   \n",
       "Topic 4             shot play  martina hingis      backhand line   \n",
       "Topic 5         really really   play backhand         play grass   \n",
       "Topic 6   large number winner    finish point         style play   \n",
       "\n",
       "                 Word 12                Word 13      Word 14  \\\n",
       "Topic 0  winner unforced  winner unforced error  average mph   \n",
       "Topic 1     volley skill         favourite shot     hit shot   \n",
       "Topic 2   martina hingis            capable hit  nigel sears   \n",
       "Topic 3    main weakness          backhand line     shot hit   \n",
       "Topic 4   favourite shot             style play  tennis like   \n",
       "Topic 5       clay court             grass hard  speed court   \n",
       "Topic 6        win point       aggression score   grand slam   \n",
       "\n",
       "                     Word 15         Word 16            Word 17  \\\n",
       "Topic 0    double experience        wta tour    allow serve ace   \n",
       "Topic 1         hit powerful     serve major      note powerful   \n",
       "Topic 2  offensive baseliner     sharp angle          game base   \n",
       "Topic 3             lot ball       ball play  aggressive player   \n",
       "Topic 4          prepare hit  break opponent         slice drop   \n",
       "Topic 5    forehand backhand  backhand solid   primary strength   \n",
       "Topic 6           hard court  backhand serve         game style   \n",
       "\n",
       "                     Word 18               Word 19  \n",
       "Topic 0   create opportunity             drop shot  \n",
       "Topic 1        center border  border center border  \n",
       "Topic 2  martina navratilova         tennis player  \n",
       "Topic 3         point player           court title  \n",
       "Topic 4      slice drop shot           play tennis  \n",
       "Topic 5        surface grass         kim clijsters  \n",
       "Topic 6           rarely win           speed court  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=7, max_iter=10)\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=20)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a2a4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmtoolkit\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "def topic_model_coherence_generator(topic_num_start=2,\n",
    "                                    topic_num_end=10,\n",
    "                                    norm_corpus='',\n",
    "                                    cv_matrix='',\n",
    "                                    cv=''):\n",
    "    norm_corpus_tokens = [doc.split() for doc in norm_corpus]\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "\n",
    "    for i in range(topic_num_start, topic_num_end):\n",
    "        print(i)\n",
    "        cur_lda = LatentDirichletAllocation(n_components=i,\n",
    "                                            max_iter=10000,\n",
    "                                            random_state=0)\n",
    "        cur_lda.fit_transform(cv_matrix)\n",
    "        cur_coherence_score = metric_coherence_gensim(\n",
    "            measure='c_v',\n",
    "            top_n=20,\n",
    "            topic_word_distrib=cur_lda.components_,\n",
    "            dtm=cv.fit_transform(norm_corpus),\n",
    "            vocab=np.array(cv.get_feature_names()),\n",
    "            texts=norm_corpus_tokens)\n",
    "        models.append(cur_lda)\n",
    "        coherence_scores.append(np.mean(cur_coherence_score))\n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5809dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  numerator = (co_occur_count / num_docs) + EPSILON\n",
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:203: RuntimeWarning: invalid value encountered in true_divide\n",
      "  denominator = (w_prime_count / num_docs) * (w_star_count / num_docs)\n",
      "/Users/liuyiwu/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_doc_prob = co_occur_count / num_docs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "models, coherence_scores = topic_model_coherence_generator(\n",
    "    2, 10, norm_corpus=playing_style, cv=tfidf_model, cv_matrix=tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d387e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2550af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf scores: \n",
      " [('serve', 9.800798410725022), ('hit', 8.772963184616527), ('play', 7.724640209730993), ('backhand', 7.125316325278012), ('shot', 7.004139243452403), ('forehand', 6.606944987566251), ('court', 6.425613702424704), ('game', 5.9874474789394565), ('winner', 5.741307356214546), ('player', 5.306744007768669), ('point', 5.23147102461234), ('opponent', 4.838503770789364), ('allow', 4.806933249995407), ('style', 4.686196673599501), ('powerful', 4.2951030142223985), ('surface', 4.245227421544899), ('aggressive', 4.220549115624489), ('strong', 4.125513123184971), ('groundstrokes', 3.9263384990454027), ('net', 3.8181619815670427), ('use', 3.796738125566304), ('ball', 3.794929280676019), ('return', 3.701067568416116), ('match', 3.651519795781254), ('power', 3.583114396839136), ('double', 3.5028298488931338), ('know', 3.432142212901573), ('hard', 3.3004223633813075), ('clay', 3.2698650177108854), ('slice', 3.2364250689916543), ('second', 3.097174026771613), ('grass', 3.066089829137491), ('rally', 3.065559423685022), ('speed', 3.0016766036429274), ('mph', 3.00047065919026), ('error', 2.9023722190245875), ('high', 2.8662425073095275), ('baseline', 2.763011471785764), ('open', 2.720050628740602), ('good', 2.6751566025445586), ('make', 2.6628115615987236), ('ace', 2.644686468548669), ('note', 2.623645590460357), ('great', 2.606691917704387), ('like', 2.5784106091844765), ('flat', 2.5590456016468512), ('wta', 2.553648400808027), ('unforced', 2.535362190712657), ('say', 2.5262359485664567), ('coach', 2.492890800952064)]\n"
     ]
    }
   ],
   "source": [
    "tfidf_model1 = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_lemmatization)\n",
    "\n",
    "tfidf_matrix1 = tfidf_model1.fit_transform(playing_style) #fit the vectorizer to synopses\n",
    "\n",
    "tf_selected_words1 = tfidf_model1.get_feature_names()\n",
    "\n",
    "top_n = 50\n",
    "print('tf_idf scores: \\n', sorted(list(zip(tfidf_model1.get_feature_names(), \n",
    "                                             tfidf_matrix1.sum(0).getA1())), \n",
    "                                 key=lambda x: x[1], reverse=True)[:top_n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
